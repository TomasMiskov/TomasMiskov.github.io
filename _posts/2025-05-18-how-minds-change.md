---
layout: post
title: How Minds Change
category: book-reflection
---

### Rating
**8.5/10** In the middle of the book I was going to give it a 7 out of 10, but then came last two chapters where you get super practical guides on how to have effective conversations and that bumped my rating up to a solid 8.5. It's pretty much a more focused version of *Thinking Fast and Slow*; more focused on persuasion and mental biases around opinion and attitude formation.

### Synopsis
Both practical and theoretical guide to debating. 

### Notes

#### Intro
- evolution favored those individuals who within their social group were able to reach consensus. The groups that were able to reach consensus on how to hunt, where to camp, etc. outlived those who couldn't agree. We are thus descendants of apes that are innately passionate about persuading others of our *"truth"* when we think our group is steering off course
- societal beliefs in things like same-sex marriage or wider politics seem to be a kind of *punctuated equilibria*. That's a term from evolutionary biology where for a long stretches of time and idea sticks and doesn't change much. Then suddenly, some *evolutionary* pressure rises and the society-wide opinion flips within a short period of time
	- *"the speed of change is inversely proportional to the strength of our certainty, and certainty is a feeling: somewhere between an emotion and a mood, more akin to hunger than logic."* (p. 16)
- a question that might help you persuade someone about whatever topic you are arguing about is: *"Why do I want to change their mind?"*
	- the answer might be because I love them, or because I think they have fallen victim to the Russian trolls on Facebook - whatever it is, it might help you lover the heat and keep it more of a conversation rather than an argument

#### Chapter 1: Post-truth
- the first chapter is about Charlie Veitch, a former conspiracy theorist who is among a very few people to publicly change his mind about 9/11 being an inside job
	- just a cool story but sets up the book well - why did he change his mind but others did not?

#### Chapter 2: Deep canvassing
- there is no fact and no single piece of information that can change somebody's mind. The only way a mind can change is by self-introspection, by walking yourself through your reasoning steps, spotting a gap, pausing, and then deciding that actually, you would like to update the way you see things
- when in conversation with someone, not a debate or an argument, you want their story to be the main piece, not yours. You want to present the topic you'd like to talk about and your general stance but then you want to invite them to tell you their whys and preferably make them go through their own reasoning process
- once people see that their ideas come from somewhere, they can start asking themselves "have I learned something since the last time I considered this topic?"
	- minds change in introspection and we don't introspect enough! 
- basic deep canvassing approach/script that worked well for same-sex marriage topic
	- tell the person you are interested in their opinions
	- ask them where they stand on same-sex marriage on a scale of 0 to 10 
	- acknowledge and do not challenge their volunteered reasons
	- show them a video of a gay couple talking a about the problems they encounter because they cannot get married
		- goal is to make the subject feel uneasy about their stance on the issue
	- ask them if they changed their rating (0-10)
	- ask for reasons why they did or did not change their rating
	- now try to elicit a personal experience from their own life that could make them realize that their own reasoning is contradictory or outdated
	- talk through the story they volunteer
	- provide a *"connecting on values"* moment; simply provide a personal conclusion that isn't about picking a fight but is a statement on which both of you can agree
		- regardless of how much you feel they might have changed their opinion by now
	- conclude by asking again where they stand on a scale from 0 to 10
- *belief-change blindness:* when people are unaware that their arguments from the beginning of the conversation do not match the ones at the end of it
	- this is what happens during successful deep-canvassing conversations; people change their minds without realizing. They smoothly tip over from slightly against to slightly for 
- again, to change minds we need a chance to introspect on the often implicit and long-held chain of arguments for our opinion. Only through introspection we can find gaps in the argumentation since without it we remain overconfident. And that overconfidence translates to certainty which allows us to hold extremist views
	- but in a world of constant distractions (algorithm going brrrr), what percentage of population is actually introspecting at all?
- the above is related to the psychological phenomenon of *illusion of explanatory depth*
	- when asked about how well you know the inner workings of everyday objects like a fridge or a toilet you are more likely to overstate your confidence than when you are ask to detail the step-by-step inner workings of the same objects
- also, perspective taking, showing subjects an emotionally charged video, isn't about making them feel bad and thus change their mind. Quite the opposite. Everybody already knows that prejudice is bad, but that's a high-level concept. Taking perspective of someone who is being ostracized makes the high-level concept much more visceral and personal. It connects the concept to reality

#### Chapter 3: Socks and Crocs
- *"the world as you experience it is a simulation running inside your skull, a waking dream"*
	- *"we each live in a virtual landscape of perpetual imagination and self-generated illusion, a hallucination informed over our lifetimes by our senses and thoughts about them, updated continuously as we bring in new experiences via those senses and think new thoughts about what we have sensed."*
- no single creature can experience reality as a whole, we all have different sensory organs and expertise, there is no true objective reality for all of us (all humans or all animals or all beings)
	- but because of this, we deem that which we can perceive as the only thing that there is
		- but what if there is more? we know in fact there is, e.g. ultraviolet light, but how about souls? ghosts?
			- I'm just musing here ;)
- *"[Blakemore & Cooper (1970)](https://www.researchgate.net/figure/Blakemore-Cooper-1970-demonstrated-that-a-cat-reared-during-its-early-life-in-an_fig1_228591147) demonstrated that a cat, reared during its early life in an environment which contained no horizontal stripes, would fail to develop neurons in the visual system which respond to horizontal edges."*
- because all reality is *virtual*, generated internally in the observer's skull, the consensus reality is mostly the result of geography
	- *"people who grow up in similar environments around similar people tend to have similar brains and thus similar virtual realities"*
- there are about 30 processing steps between a light hits our retinas and our brains interpret it as a specific picture
	- for a lemon, we all agree it's yellow not because it actually is yellow (or is it?) but because our brains are all wired roughly the same and so we interpret those specific wavelengths of light that the lemon reflects as yellow
	- but sometimes in these 30 steps there is some ambiguity in possible interpretations. Then our brains, unconsciously and automatically, disambiguate based on our past experiences. We then reach a certain conclusion with absolute certainty and we cannot comprehend how someone else could see something else (think of The Dress meme from 2015)
	- that's where disagreements that no discussion can change originate. To change that, we need to pause and go one meta-level higher
		- what were my assumptions? what were my priors? and what were the assumptions and priors of the other person I am disagreeing with?
- 4 steps on the ladder of (scientific) understanding:
	- description -> explanation -> prediction -> creation
- *"cognitive empathy": an understanding that what others experience as the truth arrives in their minds unconsciously, so arguments over conclusions are often waste of time.*

#### Chapter 4: Disequilibrium
- there's an interesting thought experiment about an "intelligent" machine that only works by counting tree rings on a felled tree by Steven Pinker
- *a brain sits in a "soup" of dopamine, and from one moment to the next the concertation of the soup influences how motivated you feel to remain on task or abandon it for another*
- epistemology: study of knowledge itself; facts, fictions, rationalizations, justifications, rationality, logic...
- *"until we know we are wrong, being wrong feels exactly like being right"*
	- !!!
- when we create causal narratives the brain fills holes in reality with provisional explanations - if there is a link missing, we make something plausible up. If enough people make up a similar link, we can end up in situation where shared consensus reality is actually just a figment of group imagination
	- think astrology, weather proverbs, eugenics etc.
- it takes many counter examples for our brains to even start considering that our current model of reality might be wrong
	- playing cards experiment with fake card colors/suits (30% of fake cards was a tipping point at which people started to consider the possibility that they are actually seeing fake cards)
- many people completely change after a cancer diagnosis or near-death experience. It's attributed to the fact that an event like that completely disrupts their world-view up until that point and so they become open to questioning everything they believed in. The magnitude of the experience is completely off the charts so it becomes plausible that everything else below this event in terms of novelty might have also been wrong

#### Chapter 5: Westboro
- when people leave a cult they usually don't leave because they have changed their opinions while still inside the cult. They leave for other reasons, like bullying or restrictions put on them by the cult's rules. Only once they are outside and free of the peer pressure, they begin to explore and change their worldviews
- people also leave the cult only when there is some expected group on the outside that will take them as a new member - be it a family or some friends they have on the outside. Otherwise it's incredibly difficult for highly social creatures like us to exit the only group we are part of, even if it hurts us to be a member
	- although internally loosing a sense of community might be the first trigger for seeking a way out
- SURFPAD
	- in moments of uncertainty we often don't feel uncertain because the brain uses our priors t disambiguate without our knowledge. When that happens, it can make the people who see the world differently seem deluded or insane

#### Chapter 6: The truth is tribal
- it's incredibly easy to create imaginary groups that people identify with. In lab experiments, people can be randomly assigned to those who overestimated or those who underestimated a random number. Then if given a choice about distributing some monetary rewards, instead of choosing and equally high reward for both groups, people will readily choose a lesser reward in absolute terms but one that gives "their" group a relatively higher amount
	- absolutely insane! 
- *humans value being good members of their groups much more than they value being right, so much so that as long as the group satisfies those needs, we will choose to be wrong if it keeps us in good standing with our peers*
	- the longer vs. shorter line experiment with actors deliberately lying
- in times of great conflict individuals will work extra hard to identify themselves as part of one of the groups to stay safe
	- in such times anything can become a sign of loyalty, even holding a thought or opinion that's a blatant lie
- when it comes to neutral topics, like volcanoes or elephants, people trust what the experts have to say and they don't think the facts are debatable. But if a topic is emotionally charged, or is part of a signal that defines your group membership, even facts are debatable 
	- and this is actually very rational for social animals like us. When holding an opposing opinion may cost you your friends, family or a job, it's rational to debate even the facts

#### Chapter 7: Arguing
- confirmation bias is when a single piece of confirmatory evidence makes us belief our conviction is true and we stop searching for counter examples to make in fact sure that we are 100% true
	- it's measuring your blood pressure and getting a suspiciously high first reading, on second reading your blood pressure is closer to the normal range so you don't do the 3rd reading because you have confirmed for yourself what you wanted - namely that your blood pressure is in normal range
	- or better yet "when the bathroom scale gives us bad news, we reweigh ourselves a few times to make sure. When it gives us good news, we step off and go about our day."
- because of our evolutionary history, we have developed a premotion of trusting our peers by default but remaining constantly vigilant for bad information
	- this helped us stay safe and survive in a larger group of early hominids but allowed us to also "think for ourselves"
	- as time progressed, we then needed a way to discuss ideas and opinions, not just share them and accept/reject them, so we developed better language and with it "arguing"
- *"when you argue with yourself, you win"*
	- brains are very shallow and weak when we argue for ourselves, inside our heads. They will come up mostly with confirmatory arguments. We need a trusted peer to poke holes into our theories, present opposite points of view
		- I think this is super clear when we have a theory or an idea we have been thinking about lately and then we decide to tell it to a friend. Suddenly an onslaught of arguments comes, at least from my friends, and I realize my idea hasn't been as eloquent, well-developed and bullet proof as I thought so
- you would think that the above is an evolutionary failure of our brains. Shouldn't we be especially good at analyzing our own arguments and thoroughly deciding what's true, what's safe and what's dangerous? - in order to survive!
	- well, we are social animals first and foremost, so we are in fact evolved to produce our own ideas and opinions quickly and effortlessly, and just than battle it out on the argumentative battlefield with our peers. The different counter arguments, lines of thoughts, suggestions and considerations are supposed, by design, to happen between ourselves, not within ourself

#### Chapter 8: Persuasion
- facts can in fact persuade people, but the person has to be motivated to listen to the facts, they need to be on the *central route* and need to be ready to elaborate in their own heads
	- the alternative is the *peripheral route* that's when people are persuaded by emotions, e.g. a famous actor selling you a product or a bag of chips being advertised as instant happiness
	- so in order to persuade people with facts, you first need to prime them to be ready for elaboration and thinking, which is not the default state. Thus, this persuasion tactic is more difficult than the peripheral route, but research showed that the effects are more enduring
	- peripheral persuasion is great for marketing and sales, but since it's less enduring, the marketing and sales tactics need to be constantly updated and changed to keep the person engaged, amused and happy - out of the central route
	- to use the central route we need to asks ourselves
		- what motivates the person?
		- are they knowledgeable?
		- are they distracted by something?
		- is the message I am trying to share threatening to their identity? (it cannot be)
- another fact is that people want to be correct. It feels good. But instead of actually checking and thinking if they are correct, they will quickly jump to conclusions and use all kinds of heuristics to make themselves feel as if they are in fact correct
	- when you say "This is the best film of 2025.", you mean it, you feel it, it feels like a fact.
- a persuasive message is more likely to succeed if:
	- the communicator seems trustworthy, credible and reliable (the *who* piece)
	- the message is paired with popular counterarguments, a two-sided communication (the *what* piece)
		- but which side should come first? the one that the audience is most inline with. Saying *"I know you don't want to go to sleep, but you have to go to school in the morning." is far more effective than "You have to go to school in the morning, so you better go to sleep."*
	- the message must match the processing abilities and motivations of its audience (the *to whom* piece)
		- make it simple and impactful to people's lives
		- or present facts as rhetorical questions "wouldn't it be nice if marijuana was legal?" instead of "Do you think marijuana should be legal?"
			- the former has a higher chance of invoking some justification for their attitudes while the latter just primes them to tell you what they think, without thinking about it (!)
	- the message should fit the medium through which it is conveyed (the *where* piece)
		- something else works in a video than in a book than in a conversation

#### Chapter 9: Street Epistemology
- street epistemology started as a YouTube channel of a guy talking to religious people on the street, trying to persuade them that religion is flawed. Over the years he developed a technique that can be used on any claim that a person might have and you would like to challenge
	- the general template is: *"clear up exactly what you are talking about, then figure out the reasons that they are giving, and then explore the reliability of the method that they are using to get to their conclusions"*
- the full steps of street epistemology talk are:
	1. Establish rapport and ask for consent to explore their reasoning
	2. Ask for a claim
	3. Confirm the claim by repeating it back in your own words. Ask if you've done a good job. Repeat till they are satisfied.
	4. Clarify their definitions. Use those definitions, not yours!
	5. Ask for a numerical measure of confidence in their claim
	6. Ask what reasons they have to hold that level of confidence
	7. Ask what method they've used to judge the quality of their reasons. Focus on that method for the remainder of the conversation
	8. Listen, summarize, repeat
	9. Wrap up and wish them well
- the main goal here is to kind of be their therapist, you can call it *guided metacognition*; encouraging a person to think about their own thinking, but only after they've used their own reasoning to produce a claim and present justifications
- it's really important to get to the actual bottom of what their reasons are. You can do so by presenting a hypothetical scenario and asking if a resolution of this scenario would nudge them at all. Example: *"I'm not an expert in this but if we had people from aviation, experts that we both trusted, and they could spend ten hours with us to explain the intricacies of flight travel and how this can actually work in a global model, would it influence your confidence in any way?"*
- the goal is never to discuss facts, it's always good to deflect the discussion of facts and instead use hypotheticals and then focus on their metacognition
- another important concept in conversations is to constantly assure the other person you are not there to *"get them"*. You also want to make sure they don't see you as a member of *them*. And you should do the same, try your best to not frame the person as *"them"*
	- it's us vs the problem
- the alternative method to street epistemology involves the following steps:
	1. Build rapport and ask for consent
	2. Ask: On a scale of one to ten, how likely are they to vaccinate? If one, ask: Why would other people, who aren't hesitant, be higher on that scale?
	3. If above one, ask: Why not lower?
	4. Once they've offered their reasons, repeat them back in your own words. Ask if you've done a good job summarizing. Repeat till they are satisfied.
- the goal is never to argue the actual argument but to look at the techniques the people use to come to their conclusion; it's technique rebuttal not argument rebuttal
- *"certainty itself is an emotion"*
- the vast majority of what brain does happens beneath thought and then it's projected into consciousness. Sometimes it floats into consciousness with the calculation itself, but often it doesn't, only the feeling of certainty appears - which is obviously dangerous 
- another way to persuade someone is to not persuade them at all, just tell them a story. When we hear a story, we are not prone to argue, but that's only true if we are immersed in it. Then we can achieve *narrative transport*, which is essentially us putting ourselves into the shoes of the main character
	- for the possibility of narrative transport to occur, the story must have
		- a component that keeps your attention from wandering
		- a component that consistently evokes strong emotional reactions
		- and a component that invokes mental imagery
- *"I want to live in a world where people believe true things. But I've realized that ridicule, ebing angry and telling people that they're mistaken, is not going to help them. We're all sort of in the same boat. We're just grasping for reasons to justify the views that we've already built. Once you know that, you begin to feel empathy, you really do. You begin to have epistemic humility about what you yourself believe."*
- *"often our positions are antagonistic, but out interest align"*
	- ask yourself; Why do I want to do this? Why do you want to change a person's mind? What are you doing here? If I want to leverage the power of one hundred years of psychological research into persuasion in a way that is very effective, why? What are my goals? What are the thoughts, feelings, and values I am exerting in this dynamic?

#### Chapter 10: Social Change
- "*changing our minds became our greatest strength as a species*"
- as cities grew bigger and we became city dwellers we were suddenly part of more groups than just our family. That meant we could start thinking of changing our minds and not just believing the same things that our extended family does
	- is this why we are arguing about politics at family lunches all the time?
- large groups of people change their minds in a sequence
	- innovators -> early adopters -> mainstream -> hold-outs
	- it's a percolation/diffusion process on the social network
	- if you want to push a new idea into the mainstream, find the innovators who are well connected to many groups and first persuade them
		- actually, this was how the old thinking went, the new science says that the network as a such has to be susceptible to *breaking*. If that's the case, if the tipping points of opinion are saturated, then any so-called *innovator* will do. A random event can start a cascade of far and wide opinion change throughout the society
- *"you don't need an atom bomb to start an avalanche; once the conditions are met, any bump will do"*
- *"persistence plus luck is what changes minds, not genius. The ideas that change the world are the ones in the heads of people who refuse to give up"*